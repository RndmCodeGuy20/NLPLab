{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a20d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f594ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230c9890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  # Punkt Sentence Tokenizer. This tokenizer divides a text into a list of sentences by using\n",
    "# an unsupervised algorithm to build a model for abbreviation words,\n",
    "# collocations, and words that start sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05bc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7bc3bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'my', 'name', 'is', 'James', ',', 'how', 'are', 'you', 'doing', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello my name is James, how are you doing!\"\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2103a9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = word_tokenize(text)\n",
    "len(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb039b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'my', 'name', 'is', 'James', ',', 'how', 'are', 'you', 'doing', '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd26d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be3b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f553c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello my name is James, how are you doing!', 'I am good.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello my name is James, how are you doing! I am good.\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc416cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = sent_tokenize(text)\n",
    "len(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "446015db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello my name is James, how are you doing!', 'I am good.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b66d827d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c6f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('document.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "928273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "161a3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0d6d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The texts, videos, images which cannot be represented in a tabular form (or in any consistent structured data model) constitute unstructured Data.',\n",
       " 'They hold the key to unraveling powerful information\\n\\nTo process and interpret the unstructured text data, we use NLP.',\n",
       " 'NLP has a wide number of applications in the real world.',\n",
       " 'Sentiment analysis\\n    Speech recognition\\n    Sentiment Analysis\\n    Text Classification\\n    Machine Translation\\n    Semantic Search\\n    News/article Summarization\\n    Answering Questions']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c1f7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029386e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy\n",
    "\n",
    "# It is the most trending and advanced library for implementing NLP today. \n",
    "# It is many distinct features that provide clear advantage for processing text data and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c632de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.1.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip\n",
    "install\n",
    "spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21d71f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  DEPRECATION: miniful is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  DEPRECATION: fst-pso is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading gensim-4.3.0-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.22.3)\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Collecting Cython==0.29.32\n",
      "  Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "     -------------------------------------- 986.3/986.3 kB 6.9 MB/s eta 0:00:00\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.1/67.1 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.1)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.10.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.1.1)\n",
      "Installing collected packages: Cython, simpful, miniful, fst-pso, pyfume, FuzzyTM, gensim\n",
      "  Running setup.py install for miniful: started\n",
      "  Running setup.py install for miniful: finished with status 'done'\n",
      "  Running setup.py install for fst-pso: started\n",
      "  Running setup.py install for fst-pso: finished with status 'done'\n",
      "Successfully installed Cython-0.29.32 FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 simpful-2.10.0\n"
     ]
    }
   ],
   "source": [
    "pip\n",
    "install\n",
    "gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9881acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997f0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b853e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting text into a spaCy object\n",
    "raw_text = 'NLP is a very powerful tool'\n",
    "text_doc = nlp(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17aee6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         Alpha Space Stop Punct\n",
      "It         : True False True False\n",
      "was        : True False True False\n",
      "amazing    : True False False False\n",
      "!          : False False False True\n",
      "It         : True False True False\n",
      "is         : True False True False\n",
      "a          : True False True False\n",
      "great      : True False False False\n",
      "pleasure   : True False False False\n",
      "to         : True False True False\n",
      "be         : True False True False\n",
      "a          : True False True False\n",
      "part       : True False True False\n",
      "of         : True False True False\n",
      "the        : True False True False\n",
      "band       : True False False False\n",
      ".          : False False False True\n"
     ]
    }
   ],
   "source": [
    "# Accessing information about tokens through the attributes\n",
    "\n",
    "random_text = 'It was amazing! It is a great pleasure to be a part of the band.'\n",
    "random_text_doc = nlp(random_text)\n",
    "print(\"Text\".ljust(10), ' ', \"Alpha\", \"Space\", \"Stop\", \"Punct\")\n",
    "for token in random_text_doc:\n",
    "    print(token.text.ljust(10), ':', token.is_alpha, token.is_space, token.is_stop, token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db790bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
